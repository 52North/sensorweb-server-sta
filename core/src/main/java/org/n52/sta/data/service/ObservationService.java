/*
 * Copyright (C) 2018-2020 52Â°North Initiative for Geospatial Open Source
 * Software GmbH
 *
 * This program is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 as published
 * by the Free Software Foundation.
 *
 * If the program is linked with libraries which are licensed under one of
 * the following licenses, the combination of the program with the linked
 * library is not considered a "derivative work" of the program:
 *
 *     - Apache License, version 2.0
 *     - Apache Software License, version 1.0
 *     - GNU Lesser General Public License, version 3
 *     - Mozilla Public License, versions 1.0, 1.1 and 2.0
 *     - Common Development and Distribution License (CDDL), version 1.0
 *
 * Therefore the distribution of the program linked with libraries licensed
 * under the aforementioned licenses, is permitted by the copyright holders
 * if the distribution is compliant with both the GNU General Public
 * License version 2 and the aforementioned licenses.
 *
 * This program is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General
 * Public License for more details.
 */

package org.n52.sta.data.service;

import java.math.BigDecimal;
import java.util.Collections;
import java.util.Date;
import java.util.Optional;
import java.util.Set;
import java.util.stream.Collectors;

import javax.persistence.EntityManager;
import javax.persistence.criteria.Predicate;

import org.hibernate.Hibernate;
import org.hibernate.query.criteria.internal.CriteriaBuilderImpl;
import org.joda.time.DateTime;
import org.n52.janmayen.http.HTTPStatus;
import org.n52.series.db.beans.AbstractDatasetEntity;
import org.n52.series.db.beans.AbstractFeatureEntity;
import org.n52.series.db.beans.BooleanDataEntity;
import org.n52.series.db.beans.CategoryDataEntity;
import org.n52.series.db.beans.CompositeDataEntity;
import org.n52.series.db.beans.CountDataEntity;
import org.n52.series.db.beans.DataEntity;
import org.n52.series.db.beans.DatasetAggregationEntity;
import org.n52.series.db.beans.DatasetEntity;
import org.n52.series.db.beans.QuantityDataEntity;
import org.n52.series.db.beans.TextDataEntity;
import org.n52.series.db.beans.parameter.observation.ObservationParameterEntity;
import org.n52.series.db.beans.sta.LocationEntity;
import org.n52.shetland.filter.ExpandFilter;
import org.n52.shetland.filter.ExpandItem;
import org.n52.shetland.filter.FilterFilter;
import org.n52.shetland.oasis.odata.query.option.QueryOptions;
import org.n52.shetland.ogc.om.OmConstants;
import org.n52.shetland.ogc.sta.StaConstants;
import org.n52.shetland.ogc.sta.exception.STACRUDException;
import org.n52.shetland.ogc.sta.exception.STAInvalidQueryException;
import org.n52.shetland.ogc.sta.model.STAEntityDefinition;
import org.n52.sta.data.query.ObservationQuerySpecifications;
import org.n52.sta.data.repositories.DatastreamRepository;
import org.n52.sta.data.repositories.EntityGraphRepository;
import org.n52.sta.data.repositories.LocationRepository;
import org.n52.sta.data.repositories.ObservationParameterRepository;
import org.n52.sta.data.repositories.ObservationRepository;
import org.n52.sta.data.service.util.CollectionWrapper;
import org.n52.sta.data.service.util.FilterExprVisitor;
import org.n52.sta.data.service.util.HibernateSpatialCriteriaBuilderImpl;
import org.n52.sta.serdes.util.ElementWithQueryOptions;
import org.n52.sta.utils.IdGenerator;
import org.n52.svalbard.odata.core.expr.Expr;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.context.annotation.DependsOn;
import org.springframework.data.domain.Page;
import org.springframework.data.jpa.domain.Specification;
import org.springframework.http.HttpMethod;
import org.springframework.stereotype.Component;
import org.springframework.transaction.annotation.Transactional;

/**
 * @author <a href="mailto:j.speckamp@52north.org">Jan Speckamp</a>
 */
@Component
@DependsOn({"springApplicationContext"})
@Transactional
public class ObservationService
        extends AbstractSensorThingsEntityServiceImpl<ObservationRepository<DataEntity<?>>, DataEntity<?>> {

    private static final ObservationQuerySpecifications oQS = new ObservationQuerySpecifications();
    private static final Logger LOGGER = LoggerFactory.getLogger(ObservationService.class);
    protected final DatastreamRepository datastreamRepository;
    protected final ObservationParameterRepository parameterRepository;
    private final String OBS_TYPE_SENSORML_OBSERVATION =
            "http://www.52north.org/def/observationType/OGC-OM/2.0/OM_SensorML20Observation";
    private final Class entityClass;

    @Autowired
    public ObservationService(ObservationRepository<DataEntity<?>> repository,
                              EntityManager em,
                              DatastreamRepository datastreamRepository,
                              ObservationParameterRepository parameterRepository) {
        super(repository, em, DataEntity.class);
        this.entityClass = DataEntity.class;
        this.datastreamRepository = datastreamRepository;
        this.parameterRepository = parameterRepository;
    }

    @Override
    public ElementWithQueryOptions getEntity(String id, QueryOptions queryOptions) throws STACRUDException {
        try {
            DataEntity<?> entity =
                    getRepository().findByStaIdentifier(id, createFetchGraph(queryOptions.getExpandFilter())).get();
            this.fetchValueIfCompositeDataEntity(entity);
            if (queryOptions.hasExpandFilter()) {
                return this.createWrapper(fetchExpandEntitiesWithFilter(entity, queryOptions.getExpandFilter()),
                                          queryOptions);
            } else {
                return this.createWrapper(entity, queryOptions);
            }
        } catch (RuntimeException | STAInvalidQueryException e) {
            throw new STACRUDException(e.getMessage(), e);
        }
    }

    @Override
    public CollectionWrapper getEntityCollection(QueryOptions queryOptions) throws STACRUDException {
        try {
            Page<DataEntity<?>> pages = getRepository().findAll(getFilterPredicate(entityClass, queryOptions),
                                                                createPageableRequest(queryOptions),
                                                                queryOptions.hasCountFilter() &&
                                                                        queryOptions.getCountFilter().getValue(),
                                                                createFetchGraph(queryOptions.getExpandFilter()));
            pages.forEach(this::fetchValueIfCompositeDataEntity);
            return createCollectionWrapperAndExpand(queryOptions, pages);
        } catch (RuntimeException e) {
            throw new STACRUDException(e.getMessage(), e);
        }
    }

    @Override
    protected Page getEntityCollectionByRelatedEntityRaw(String relatedId,
                                                         String relatedType,
                                                         QueryOptions queryOptions)
            throws STACRUDException {
        try {
            Page<DataEntity<?>> pages = getRepository()
                    .findAll(byRelatedEntityFilter(relatedId, relatedType, null)
                                     .and(getFilterPredicate(entityClass, queryOptions)),
                             createPageableRequest(queryOptions),
                             queryOptions.hasCountFilter() && queryOptions.getCountFilter().getValue(),
                             createFetchGraph(queryOptions.getExpandFilter()));
            pages.forEach(this::fetchValueIfCompositeDataEntity);
            if (queryOptions.hasExpandFilter()) {
                return pages.map(e -> {
                    try {
                        em.detach(e);
                        return fetchExpandEntitiesWithFilter(e, queryOptions.getExpandFilter());
                    } catch (STACRUDException | STAInvalidQueryException ex) {
                        throw new RuntimeException(ex);
                    }
                });
            } else {
                return pages;
            }
        } catch (RuntimeException e) {
            throw new STACRUDException(e.getMessage(), e);
        }
    }

    @Override
    public DataEntity<?> getEntityByIdRaw(Long id, QueryOptions queryOptions) throws STACRUDException {
        DataEntity<?> entity = super.getEntityByIdRaw(id, queryOptions);
        fetchValueIfCompositeDataEntity(entity);
        return entity;
    }

    @Override
    public DataEntity<?> getEntityByRelatedEntityRaw(String relatedId,
                                                     String relatedType,
                                                     String ownId,
                                                     QueryOptions queryOptions) throws STACRUDException {
        DataEntity<?> entity =
                super.getEntityByRelatedEntityRaw(relatedId, relatedType, ownId, queryOptions);
        fetchValueIfCompositeDataEntity(entity);
        return entity;
    }

    @Override
    protected EntityGraphRepository.FetchGraph[] createFetchGraph(ExpandFilter expandOption) {
        return new EntityGraphRepository.FetchGraph[] {
                EntityGraphRepository.FetchGraph.FETCHGRAPH_PARAMETERS
        };
    }

    @Override
    protected DataEntity<?> fetchExpandEntitiesWithFilter(DataEntity<?> returned,
                                                          ExpandFilter expandOption)
            throws STACRUDException, STAInvalidQueryException {
        for (ExpandItem expandItem : expandOption.getItems()) {
            String expandProperty = expandItem.getPath();
            switch (expandProperty) {
            case STAEntityDefinition.DATASTREAM:
                DatasetEntity datastream = (DatasetEntity) getDatastreamService()
                        .getEntityByRelatedEntityRaw(returned.getStaIdentifier(),
                                                     STAEntityDefinition.OBSERVATIONS,
                                                     null,
                                                     expandItem.getQueryOptions());
                returned.setDataset(datastream);
                break;
            case STAEntityDefinition.FEATURE_OF_INTEREST:
                AbstractFeatureEntity<?> foi = getFeatureOfInterestService()
                        .getEntityByDatasetIdRaw(returned.getDataset().getId(), expandItem.getQueryOptions());
                returned.setFeature(foi);
                break;
            default:
                throw new STAInvalidQueryException(String.format(INVALID_EXPAND_OPTION_SUPPLIED,
                                                                 expandProperty,
                                                                 StaConstants.OBSERVATIONS));
            }
        }
        return returned;
    }

    @Override
    public Specification<DataEntity<?>> byRelatedEntityFilter(String relatedId,
                                                              String relatedType,
                                                              String ownId) {
        Specification<DataEntity<?>> filter;
        switch (relatedType) {
        case STAEntityDefinition.DATASTREAMS: {
            filter = ObservationQuerySpecifications.withDatastreamStaIdentifier(relatedId);
            break;
        }
        case STAEntityDefinition.FEATURES_OF_INTEREST: {
            filter = ObservationQuerySpecifications.withFeatureOfInterestStaIdentifier(relatedId);
            break;
        }
        default:
            throw new IllegalStateException(String.format(TRYING_TO_FILTER_BY_UNRELATED_TYPE, relatedType));
        }
        if (ownId != null) {
            filter = filter.and(oQS.withStaIdentifier(ownId));
        }
        return filter;
    }

    @Override
    public DataEntity<?> createOrfetch(DataEntity<?> entity) throws STACRUDException {
        synchronized (getLock(entity.getStaIdentifier())) {
            DataEntity<?> observation = entity;
            if (!observation.isProcessed()) {
                observation.setProcessed(true);
                check(observation);

                // Fetch dataset and check if FOI matches to reuse existing dataset
                AbstractDatasetEntity datastream = datastreamRepository
                        .findByStaIdentifier(entity.getDataset().getStaIdentifier(),
                                             EntityGraphRepository.FetchGraph.FETCHGRAPH_FEATURE)
                        .orElseThrow(() -> new STACRUDException("Unable to find Datastream!"));
                AbstractFeatureEntity<?> feature = createOrfetchFeature(observation, datastream.getPlatform().getId());

                // Check all subdatasets for a matching  dataset
                Set<DatasetEntity> datasets;
                if (datastream.getAggregation() == null && !(datastream instanceof DatasetAggregationEntity)) {
                    // We are not an aggregate so there is only one dataset to check for fit
                    datasets = Collections.singleton((DatasetEntity) datastream);
                } else {
                    datasets = datastreamRepository.findAllByAggregationId(datastream.getId())
                                                   .stream()
                                                   .map(d -> (DatasetEntity) d)
                                                   .collect(Collectors.toSet());
                }

                // Check all datasets for a matching FOI
                boolean found = false;
                for (DatasetEntity dataset : datasets) {
                    if (!dataset.hasFeature()) {
                        // We have a dataset without a feature
                        LOGGER.debug("Reusing existing dataset without FOI.");
                        dataset.setFeature(feature);
                        observation.setDataset(datastreamRepository.save(dataset));
                        found = true;
                        break;
                    } else if (feature.getId().equals(dataset.getFeature().getId())) {
                        // We have a dataset with a matching feature
                        observation.setDataset(dataset);
                        LOGGER.debug("Reusing existing dataset with matching FOI.");
                        found = true;
                        break;
                    }
                }

                if (!found) {
                    // We have not found a matching dataset so we need to create a new one
                    LOGGER.debug("Creating new dataset as none with matching FOI exists");
                    observation.setDataset(getDatastreamService().createOrExpandAggregation(datastream, feature));
                }

                // Save Observation
                DataEntity<?> data = saveObservation(observation, observation.getDataset());

                // Update FirstValue/LastValue + FirstObservation/LastObservation of Dataset + Aggregation
                updateDataset(observation.getDataset(), data);
                return data;
            }
            return observation;
        }
    }

    @Override
    public DataEntity<?> updateEntity(String id, DataEntity<?> entity, HttpMethod method)
            throws STACRUDException {
        if (HttpMethod.PATCH.equals(method)) {
            synchronized (getLock(id)) {
                Optional<DataEntity<?>> existing =
                        getRepository()
                                .findByStaIdentifier(id,
                                                     EntityGraphRepository
                                                             .FetchGraph
                                                             .FETCHGRAPH_PARAMETERS);
                if (existing.isPresent()) {
                    DataEntity<?> merged = merge(existing.get(), entity);
                    DataEntity<?> saved = getRepository().save(merged);

                    AbstractDatasetEntity datastreamEntity =
                            datastreamRepository.findById(saved.getDataset().getId()).get();

                    updateDatastreamPhenomenonTimeOnObservationUpdate(datastreamEntity, saved);
                    Hibernate.initialize(saved.getParameters());
                    return saved;
                }
                throw new STACRUDException(UNABLE_TO_UPDATE_ENTITY_NOT_FOUND, HTTPStatus.NOT_FOUND);
            }
        } else if (HttpMethod.PUT.equals(method)) {
            throw new STACRUDException(HTTP_PUT_IS_NOT_YET_SUPPORTED, HTTPStatus.NOT_IMPLEMENTED);
        }
        throw new STACRUDException(INVALID_HTTP_METHOD_FOR_UPDATING_ENTITY, HTTPStatus.BAD_REQUEST);
    }

    @Override
    public DataEntity<?> createOrUpdate(DataEntity<?> entity) throws STACRUDException {
        synchronized (getLock(entity.getStaIdentifier())) {
            if (entity.getStaIdentifier() != null && getRepository().existsByStaIdentifier(entity.getStaIdentifier())) {
                return updateEntity(entity.getStaIdentifier(), entity, HttpMethod.PATCH);
            }
            return createOrfetch(entity);
        }
    }

    @Override
    public Specification<DataEntity<?>> getFilterPredicate(Class entityClass, QueryOptions queryOptions) {
        return (root, query, builder) -> {
            Predicate defaultFilter = builder.isNull(root.get(DataEntity.PROPERTY_PARENT));
            if (!queryOptions.hasFilterFilter()) {
                // Filter out non-root observations
                // e.g. Profile-/TrajectoryObservations
                return defaultFilter;
            } else {
                FilterFilter filterOption = queryOptions.getFilterFilter();
                Expr filter = (Expr) filterOption.getFilter();
                try {
                    HibernateSpatialCriteriaBuilderImpl staBuilder =
                            new HibernateSpatialCriteriaBuilderImpl((CriteriaBuilderImpl) builder);
                    return builder.and(defaultFilter,
                                       (Predicate) filter.accept(
                                               new FilterExprVisitor<DataEntity<?>>(root, query, staBuilder)));
                } catch (STAInvalidQueryException e) {
                    throw new RuntimeException(e);
                }
            }
        };
    }

    @Override
    public String checkPropertyName(String property) {
        return oQS.checkPropertyName(property);
    }

    @Override
    public DataEntity<?> merge(DataEntity<?> existing, DataEntity<?> toMerge)
            throws STACRUDException {
        // phenomenonTime
        mergeSamplingTimeAndCheckResultTime(existing, toMerge);
        // resultTime
        if (toMerge.getResultTime() != null) {
            existing.setResultTime(toMerge.getResultTime());
        }
        // validTime
        if (toMerge.isSetValidTime()) {
            existing.setValidTimeStart(toMerge.getValidTimeStart());
            existing.setValidTimeEnd(toMerge.getValidTimeEnd());
        }
        // parameter
        if (toMerge.getParameters() != null) {
            synchronized (getLock(String.valueOf(
                    toMerge.getParameters().hashCode() + existing.getParameters().hashCode()))) {
                existing.getParameters()
                        .stream()
                        .filter(o -> o instanceof ObservationParameterEntity)
                        .map(o -> (ObservationParameterEntity) o)
                        .forEach(parameterRepository::delete);
                existing.setParameters(toMerge.getParameters());
            }
        }
        // value
        if (toMerge.getValueText() != null) {
            checkValue(existing, toMerge);
        }
        return existing;
    }

    /**
     * We touch DataEntity->value here to make sure it is fetched from the database and not lazy-loaded.
     * We cannot fetch it ourselves as any assignment to entity->value will update the database (issue delete+insert
     * statemenets).
     *
     * @param entity to be loaded
     * @return entity with not-lazy-loaded value and value->parameters
     */
    private DataEntity<?> fetchValueIfCompositeDataEntity(DataEntity<?> entity) {
        // We need to unproxy first to be able to check the type & access properties
        // As we unproxy later anyway this is no overhead.
        DataEntity<?> unproxy = (DataEntity<?>) Hibernate.unproxy(entity);
        if (unproxy instanceof CompositeDataEntity) {
            ((Set<DataEntity<?>>) unproxy.getValue())
                    .forEach(v -> Hibernate.initialize(v.getParameters())
                    );
        }
        return unproxy;
    }

    protected DataEntity castToConcreteObservationType(DataEntity<?> observation,
                                                       DatasetEntity dataset)
            throws STACRUDException {
        DataEntity data = null;
        String value = observation.getValueText();
        switch (dataset.getOMObservationType().getFormat()) {
        case OmConstants.OBS_TYPE_MEASUREMENT:
            QuantityDataEntity quantityObservationEntity = new QuantityDataEntity();
            if (value.equals("NaN") || value.equals("Inf") || value.equals("-Inf")) {
                quantityObservationEntity.setValue(null);
            } else {
                quantityObservationEntity.setValue(BigDecimal.valueOf(Double.parseDouble(value)));
            }
            data = quantityObservationEntity;
            break;
        case OmConstants.OBS_TYPE_CATEGORY_OBSERVATION:
            CategoryDataEntity categoryObservationEntity = new CategoryDataEntity();
            categoryObservationEntity.setValue(value);
            data = categoryObservationEntity;
            break;
        case OmConstants.OBS_TYPE_COUNT_OBSERVATION:
            CountDataEntity countObservationEntity = new CountDataEntity();
            countObservationEntity.setValue(Integer.parseInt(value));
            data = countObservationEntity;
            break;
        case OmConstants.OBS_TYPE_TEXT_OBSERVATION:
            TextDataEntity textObservationEntity = new TextDataEntity();
            textObservationEntity.setValue(value);
            data = textObservationEntity;
            break;
        case OmConstants.OBS_TYPE_TRUTH_OBSERVATION:
            BooleanDataEntity booleanObservationEntity = new BooleanDataEntity();
            booleanObservationEntity.setValue(Boolean.parseBoolean(value));
            data = booleanObservationEntity;
            break;
        case OBS_TYPE_SENSORML_OBSERVATION:
            org.n52.series.db.beans.SensorML20DataEntity sensorML20DataEntity = new org.n52.series.db.beans.SensorML20DataEntity();
            sensorML20DataEntity.setValue(value);
            data = sensorML20DataEntity;
            break;
        default:
            throw new STACRUDException(
                    "Unable to handle OMObservation with type: " + dataset.getOMObservationType().getFormat());
        }
        return fillConcreteObservationType(data, observation, dataset);
    }

    private void check(DataEntity<?> observation) throws STACRUDException {
        if (observation.getDataset() == null) {
            throw new STACRUDException("The observation to create is invalid. Missing datastream!",
                                       HTTPStatus.BAD_REQUEST);
        }
    }

    /**
     * Handles updating the phenomenonTime field of the associated Datastream when Observation phenomenonTime is
     * updated or deleted
     *
     * @param datastreamEntity DatstreamEntity
     * @param observation      ObservationEntity
     */
    protected void updateDatastreamPhenomenonTimeOnObservationUpdate(AbstractDatasetEntity datastreamEntity,
                                                                     DataEntity<?> observation) {
        if (datastreamEntity.getPhenomenonTimeStart() == null ||
                datastreamEntity.getPhenomenonTimeEnd() == null ||
                observation.getPhenomenonTimeStart().compareTo(datastreamEntity.getPhenomenonTimeStart()) != 1 ||
                observation.getPhenomenonTimeEnd().compareTo(datastreamEntity.getPhenomenonTimeEnd()) != -1
        ) {
            // Setting new phenomenonTimeStart
            DataEntity<?> firstObservation = getRepository()
                    .findFirstByDataset_idOrderBySamplingTimeStartAsc(datastreamEntity.getId());
            Date newPhenomenonStart = (firstObservation == null) ? null : firstObservation.getPhenomenonTimeStart();

            // Set Start and End to null if there is no observation.
            if (newPhenomenonStart == null) {
                datastreamEntity.setPhenomenonTimeStart(null);
                datastreamEntity.setPhenomenonTimeEnd(null);
            } else {
                datastreamEntity.setPhenomenonTimeStart(newPhenomenonStart);

                // Setting new phenomenonTimeEnd
                DataEntity<?> lastObservation = getRepository()
                        .findFirstByDataset_idOrderBySamplingTimeEndDesc(datastreamEntity.getId());
                Date newPhenomenonEnd = (lastObservation == null) ? null : lastObservation.getPhenomenonTimeEnd();
                if (newPhenomenonEnd != null) {
                    datastreamEntity.setPhenomenonTimeEnd(newPhenomenonEnd);
                } else {
                    datastreamEntity.setPhenomenonTimeStart(null);
                    datastreamEntity.setPhenomenonTimeEnd(null);
                }
            }
            datastreamRepository.save(datastreamEntity);
            // update parent if its part of the aggregation
            if (datastreamEntity.isSetAggregation()) {
                updateDatastreamPhenomenonTimeOnObservationUpdate(
                        datastreamRepository.findById(datastreamEntity.getAggregation()
                                                                      .getId()).get(),
                        observation);
            }
        }
    }

    @Override
    public void delete(String identifier) throws STACRUDException {
        synchronized (getLock(identifier)) {
            if (getRepository().existsByStaIdentifier(identifier)) {
                DataEntity<?> observation =
                        getRepository().findByStaIdentifier(
                                               identifier,
                                               EntityGraphRepository.FetchGraph.FETCHGRAPH_DATASET_FIRSTLAST_OBSERVATION)
                                       .get();
                deleteReferenceFromDatasetFirstLast(observation);

                if (observation.hasParameters()) {
                    observation.getParameters()
                               .forEach(entity -> parameterRepository.delete((ObservationParameterEntity) entity));
                }
                // Important! Delete first and then update else we find
                // ourselves again in search for new latest/earliest obs.
                getRepository().deleteByStaIdentifier(observation.getStaIdentifier());
                updateDatastreamPhenomenonTimeOnObservationUpdate(observation.getDataset(), observation);
            } else {
                throw new STACRUDException(UNABLE_TO_DELETE_ENTITY_NOT_FOUND, HTTPStatus.NOT_FOUND);
            }
        }
    }

    private void deleteReferenceFromDatasetFirstLast(DataEntity<?> observation) {
        // TODO get the next first/last observation and set it
        DatasetEntity dataset = observation.getDataset();
        if (dataset.getFirstObservation() != null
                && dataset.getFirstObservation().getStaIdentifier().equals(observation.getStaIdentifier())) {
            dataset.setFirstObservation(null);
            dataset.setFirstQuantityValue(null);
            dataset.setFirstValueAt(null);
        }
        if (dataset.getLastObservation() != null && dataset.getLastObservation()
                                                           .getStaIdentifier()
                                                           .equals(observation.getStaIdentifier())) {
            dataset.setLastObservation(null);
            dataset.setLastQuantityValue(null);
            dataset.setLastValueAt(null);
        }
        observation.setDataset(datastreamRepository.saveAndFlush(dataset));
    }

    private AbstractFeatureEntity<?> createOrfetchFeature(DataEntity observation,
                                                          Long thingId)
            throws STACRUDException {
        // Create feature based on Thing.location if there is no feature given
        if (!observation.hasFeature()) {
            AbstractFeatureEntity<?> feature = null;
            LocationRepository locationRepository = getLocationService().getRepository();
            Set<LocationEntity> locations = locationRepository.findAllByPlatformsIdEquals(thingId);
            for (LocationEntity location : locations) {
                if (feature == null) {
                    feature = ServiceUtils.createFeatureOfInterest(location);
                }
                if (location.isSetGeometry()) {
                    feature = ServiceUtils.createFeatureOfInterest(location);
                    break;
                }
            }
            if (feature == null) {
                throw new STACRUDException("The observation to create is invalid." +
                                                   " Missing feature or thing.location!", HTTPStatus.BAD_REQUEST);
            }
            observation.setFeature(feature);
        }
        // save feature to db
        AbstractFeatureEntity<?> feature = getFeatureOfInterestService().createOrfetch(observation.getFeature());
        observation.setFeature(feature);
        return feature;
    }

    private DataEntity<?> saveObservation(DataEntity<?> observation, DatasetEntity dataset)
            throws STACRUDException {
        DataEntity<?> data = castToConcreteObservationType(observation, dataset);
        return getRepository().save(data);
    }

    /**
     * Updates FirstValue/LastValue, FirstObservation/LastObservation, Geometry of Dataset and DatasetAggregation
     *
     * @param dataset Dataset to be updated
     * @param data    New Observation
     * @return update DatasetEntity
     * @throws STACRUDException if an error occurred
     */
    private AbstractDatasetEntity updateDataset(AbstractDatasetEntity dataset, DataEntity<?> data)
            throws STACRUDException {
        Optional<DataEntity<?>> rawObservation = getRepository().findById(data.getId());
        if (rawObservation.isPresent()) {
            synchronized (getLock(dataset.getId().toString() + "Dataset")) {
                LOGGER.debug("Updating First/Last/Geometry of of Dataset: {}", dataset.getId());
                if (!dataset.isSetFirstValueAt()
                        || dataset.isSetFirstValueAt()
                        && data.getSamplingTimeStart().before(dataset.getFirstValueAt())) {
                    dataset.setFirstValueAt(data.getSamplingTimeStart());
                    dataset.setFirstObservation(rawObservation.get());
                    if (data instanceof QuantityDataEntity) {
                        dataset.setFirstQuantityValue(((QuantityDataEntity) data).getValue());
                    }
                }
                if (!dataset.isSetLastValueAt()
                        || dataset.isSetLastValueAt()
                        && data.getSamplingTimeEnd().after(dataset.getLastValueAt())) {
                    dataset.setLastValueAt(data.getSamplingTimeEnd());
                    dataset.setLastObservation(rawObservation.get());
                    if (data instanceof QuantityDataEntity) {
                        dataset.setLastQuantityValue(((QuantityDataEntity) data).getValue());
                    }
                }
                // Update phenomenonTime
                if (dataset.getPhenomenonTimeStart() == null) {
                    dataset.setPhenomenonTimeStart(data.getPhenomenonTimeStart());
                    dataset.setPhenomenonTimeEnd(data.getPhenomenonTimeEnd());
                } else {
                    if (dataset.getPhenomenonTimeStart().after(data.getPhenomenonTimeStart())) {
                        dataset.setPhenomenonTimeStart(data.getPhenomenonTimeStart());
                    }
                    if (dataset.getPhenomenonTimeEnd().before(data.getPhenomenonTimeEnd())) {
                        dataset.setPhenomenonTimeEnd(data.getPhenomenonTimeEnd());
                    }
                }
                // Update aggregation if present
                if (dataset.getAggregation() != null) {
                    //TODO: We might need to fetch the aggregation first!
                    LOGGER.debug("Updating First/Last/Geometry of parent Aggregation: {}",
                                 dataset.getAggregation().getId());
                    updateDataset(dataset.getAggregation(), data);
                }

                return datastreamRepository.save(dataset);
            }
        } else {
            throw new STACRUDException("Could not update Dataset->firstObservation or Dataset->firstObservation. " +
                                               "Unable to find Observation with Id:" + data.getId());
        }
    }

    protected void mergeSamplingTimeAndCheckResultTime(DataEntity<?> existing, DataEntity<?> toMerge) {
        if (toMerge.getSamplingTimeEnd() != null && existing.getSamplingTimeEnd().equals(existing.getResultTime())) {
            existing.setResultTime(toMerge.getSamplingTimeEnd());
        }
        mergeSamplingTime(existing, toMerge);
    }

    private void checkValue(DataEntity<?> existing, DataEntity<?> toMerge) throws STACRUDException {
        if (existing instanceof QuantityDataEntity) {
            ((QuantityDataEntity) existing)
                    .setValue(BigDecimal.valueOf(Double.parseDouble(toMerge.getValueText())));
        } else if (existing instanceof CountDataEntity) {
            ((CountDataEntity) existing).setValue(Integer.parseInt(toMerge.getValueText()));
        } else if (existing instanceof BooleanDataEntity) {
            ((BooleanDataEntity) existing).setValue(Boolean.parseBoolean(toMerge.getValueText()));
        } else if (existing instanceof TextDataEntity) {
            ((TextDataEntity) existing).setValue(toMerge.getValueText());
        } else if (existing instanceof CategoryDataEntity) {
            ((CategoryDataEntity) existing).setValue(toMerge.getValueText());
        } else {
            throw new STACRUDException(
                    String.format("The observation value for @iot.id %s can not be updated!",
                                  existing.getStaIdentifier()),
                    HTTPStatus.CONFLICT);
        }
    }

    protected DataEntity<?> fillConcreteObservationType(DataEntity<?> data,
                                                        DataEntity<?> observation,
                                                        DatasetEntity dataset) throws STACRUDException {
        data.setDataset(dataset);
        if (observation.getStaIdentifier() != null) {
            if (getRepository().existsByStaIdentifier(observation.getStaIdentifier())) {
                throw new STACRUDException(IDENTIFIER_ALREADY_EXISTS, HTTPStatus.CONFLICT);
            } else {
                data.setIdentifier(observation.getIdentifier());
                data.setStaIdentifier(observation.getStaIdentifier());
            }
        } else {
            String uuid = generateIdentifier(observation);
            data.setIdentifier(uuid);
            data.setStaIdentifier(uuid);
        }
        data.setSamplingTimeStart(observation.getSamplingTimeStart());
        data.setSamplingTimeEnd(observation.getSamplingTimeEnd());
        data.setResultTime(observation.getResultTime());
        data.setValidTimeStart(observation.getValidTimeStart());
        data.setValidTimeEnd(observation.getValidTimeEnd());
        data.setGeometryEntity(observation.getGeometryEntity());
        data.setVerticalFrom(observation.getVerticalFrom());
        data.setVerticalTo(observation.getVerticalTo());
        return data;
    }

    private String generateIdentifier(DataEntity<?> observation) {
        StringBuffer buffer = new StringBuffer();
        buffer.append(observation.getDataset().getIdentifier())
              .append(new DateTime(observation.getSamplingTimeStart())).append("/")
              .append(new DateTime(observation.getSamplingTimeEnd())).append(observation.getValue())
              .append(new DateTime(observation.getResultTime())).append(observation.getVerticalFrom())
              .append(observation.getVerticalTo());
        return IdGenerator.generate(buffer.toString());
    }
}
